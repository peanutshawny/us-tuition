{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is university tuition so high in the US?\n",
    "\n",
    "There have been lots of news stories covering how university tuition is rising in the United States and is outpacing the financial means of students (before and after graduation). With the avaiable data from the US College Scorecard dataset, I will dive into this question and try to ascertain what is largest reason for rising tuition and produce cost-effective recommendations to alleviate the issue without harming the quality of education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## College Scorecard\n",
    "\n",
    "It's no secret that US university students often graduate with debt repayment obligations that far outstrip their employment and income prospects. While it's understood that students from elite colleges tend to earn more than graduates from less prestigious universities, the finer relationships between future income and university attendance are quite murky. In an effort to make educational investments less speculative, the US Department of Education has matched information from the student financial aid system with federal tax returns to create the College Scorecard dataset.\n",
    "\n",
    "For my purposes, I'm going to examine the relationship between school tuition and other features of the dataset, along with changes in tuition over the lifetime of the Scorecard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from file folder\n",
    "\n",
    "Since there's datasets since the inception of the scorecard (1996) that could to be read in, I created a function that goes into the data folder, reads each csv, and concatenates each one onto a dataframe. Since each year of data contains over 2000 columns, it will be best if I select only the past five years to reduce runtime. It's possible that I could lose some insights by doing this. It would also be better to transfer these csv's into something like a sqlite database, but for my purposes reading and filtering with pandas should do for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs all csv's into one file and saves it as new csv \n",
    "def read_files(in_path, out_path):\n",
    "    file_list = os.listdir(in_path)\n",
    "    output = []\n",
    "    \n",
    "    for file_name in file_list:\n",
    "        df = pd.read_csv(os.path.join(in_path, file_name))\n",
    "        \n",
    "        # adding a date column as the filename of the csv that the data point originated from\n",
    "        df['DATE'] = file_name\n",
    "        output.append(df)\n",
    "    \n",
    "    df_combined = pd.concat(output)\n",
    "    df_combined.to_csv(os.path.join(out_path, 'college_scorecard_fiveyears.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executing function to reorganize last five years of data\n",
    "read_files('D:/Python/validere_takehome/CollegeScorecard_Raw_Data/data', \n",
    "           'D:/Python/validere_takehome/CollegeScorecard_Raw_Data/combined_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNITID</th>\n",
       "      <th>OPEID</th>\n",
       "      <th>OPEID6</th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>ACCREDAGENCY</th>\n",
       "      <th>INSTURL</th>\n",
       "      <th>NPCURL</th>\n",
       "      <th>...</th>\n",
       "      <th>OMENRUP_NOTFIRSTTIME_POOLED_SUPP</th>\n",
       "      <th>OMENRYP_FULLTIME_POOLED_SUPP</th>\n",
       "      <th>OMENRAP_FULLTIME_POOLED_SUPP</th>\n",
       "      <th>OMAWDP8_FULLTIME_POOLED_SUPP</th>\n",
       "      <th>OMENRUP_FULLTIME_POOLED_SUPP</th>\n",
       "      <th>OMENRYP_PARTTIME_POOLED_SUPP</th>\n",
       "      <th>OMENRAP_PARTTIME_POOLED_SUPP</th>\n",
       "      <th>OMAWDP8_PARTTIME_POOLED_SUPP</th>\n",
       "      <th>OMENRUP_PARTTIME_POOLED_SUPP</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100654</td>\n",
       "      <td>100200</td>\n",
       "      <td>1002</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>35762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MERGED2012_13_PP.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100663</td>\n",
       "      <td>105200</td>\n",
       "      <td>1052</td>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>35294-0110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MERGED2012_13_PP.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100690</td>\n",
       "      <td>2503400</td>\n",
       "      <td>25034</td>\n",
       "      <td>Amridge University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>36117-3553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MERGED2012_13_PP.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100706</td>\n",
       "      <td>105500</td>\n",
       "      <td>1055</td>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>AL</td>\n",
       "      <td>35899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MERGED2012_13_PP.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100724</td>\n",
       "      <td>100500</td>\n",
       "      <td>1005</td>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>36104-0271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MERGED2012_13_PP.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1978 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNITID    OPEID  OPEID6                               INSTNM        CITY  \\\n",
       "0  100654   100200    1002             Alabama A & M University      Normal   \n",
       "1  100663   105200    1052  University of Alabama at Birmingham  Birmingham   \n",
       "2  100690  2503400   25034                   Amridge University  Montgomery   \n",
       "3  100706   105500    1055  University of Alabama in Huntsville  Huntsville   \n",
       "4  100724   100500    1005             Alabama State University  Montgomery   \n",
       "\n",
       "  STABBR         ZIP ACCREDAGENCY INSTURL NPCURL  ...  \\\n",
       "0     AL       35762          NaN     NaN    NaN  ...   \n",
       "1     AL  35294-0110          NaN     NaN    NaN  ...   \n",
       "2     AL  36117-3553          NaN     NaN    NaN  ...   \n",
       "3     AL       35899          NaN     NaN    NaN  ...   \n",
       "4     AL  36104-0271          NaN     NaN    NaN  ...   \n",
       "\n",
       "   OMENRUP_NOTFIRSTTIME_POOLED_SUPP  OMENRYP_FULLTIME_POOLED_SUPP  \\\n",
       "0                               NaN                           NaN   \n",
       "1                               NaN                           NaN   \n",
       "2                               NaN                           NaN   \n",
       "3                               NaN                           NaN   \n",
       "4                               NaN                           NaN   \n",
       "\n",
       "   OMENRAP_FULLTIME_POOLED_SUPP  OMAWDP8_FULLTIME_POOLED_SUPP  \\\n",
       "0                           NaN                           NaN   \n",
       "1                           NaN                           NaN   \n",
       "2                           NaN                           NaN   \n",
       "3                           NaN                           NaN   \n",
       "4                           NaN                           NaN   \n",
       "\n",
       "   OMENRUP_FULLTIME_POOLED_SUPP  OMENRYP_PARTTIME_POOLED_SUPP  \\\n",
       "0                           NaN                           NaN   \n",
       "1                           NaN                           NaN   \n",
       "2                           NaN                           NaN   \n",
       "3                           NaN                           NaN   \n",
       "4                           NaN                           NaN   \n",
       "\n",
       "   OMENRAP_PARTTIME_POOLED_SUPP  OMAWDP8_PARTTIME_POOLED_SUPP  \\\n",
       "0                           NaN                           NaN   \n",
       "1                           NaN                           NaN   \n",
       "2                           NaN                           NaN   \n",
       "3                           NaN                           NaN   \n",
       "4                           NaN                           NaN   \n",
       "\n",
       "   OMENRUP_PARTTIME_POOLED_SUPP                  DATE  \n",
       "0                           NaN  MERGED2012_13_PP.csv  \n",
       "1                           NaN  MERGED2012_13_PP.csv  \n",
       "2                           NaN  MERGED2012_13_PP.csv  \n",
       "3                           NaN  MERGED2012_13_PP.csv  \n",
       "4                           NaN  MERGED2012_13_PP.csv  \n",
       "\n",
       "[5 rows x 1978 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in files\n",
    "uni_df = pd.read_csv('D:/Python/validere_takehome/CollegeScorecard_Raw_Data/combined_data/college_scorecard_fiveyears.csv', \n",
    "                     warn_bad_lines = False)\n",
    "uni_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45180, 1978)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the shape of the data?\n",
    "uni_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, each dataset corresponds to a specific school in a specific year. There are many features to the data with many features having mixed types! This will require a good amount of cleaning and reading of the data dictionary to drop unecessary features before conducting further analysis.\n",
    "\n",
    "Looking at the data dictionary and sheer amount of features this dataset has, it would probably be best to pull useful features instead of dropping ones that aren't useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "After a read-through of the technical documentation, I selected some features that I thought would be interesting to analyze and may be related to rising tuition. Broad categories these features fit under include the location/size of the university, tuition, revenue/expenses, faculty salaries, acceptance rates, SAT averages, average debt/grants, repayment period of debt after graduation, family earnings, and earnings after graduation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['INSTNM', 'CITY', 'STABBR', 'ZIP', 'NUMBRANCH', 'PREDDEG', 'HIGHDEG', 'LOCALE', 'LOCALE2',\n",
    "                 'LATITUDE', 'LONGITUDE', 'CCBASIC', 'CCUGPROF', 'CCSIZSET', 'HBCU', 'PBI', 'NANTI', 'MENONLY',\n",
    "                 'WOMENONLY', 'RELAFFIL', 'ADM_RATE', 'SAT_AVG', 'DISTANCEONLY', 'UG', 'CURROPER',\n",
    "                 'NPT4_PUB' ,'NPT4_PRIV', 'NPT4_PROG', 'NPT4_OTHER', 'NUM4_PUB', 'NUM4_PRIV' ,'NUM4_PROG', 'NUM4_OTHER',\n",
    "                 'TUITIONFEE_IN', 'TUITIONFEE_OUT', 'TUITFTE', 'INEXPFTE', 'AVGFACSAL', 'PFTFAC', 'PCTPELL', 'PCTFLOAN', \n",
    "                  'DEP_STAT_PCT_IND', 'DEP_INC_AVG', 'IND_INC_AVG', 'GRAD_DEBT_MDN', 'WDRAW_DEBT_MDN', 'MN_EARN_WNE_P6', 'DATE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to split up the original dataframe into one that will actually be used for further analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45180, 48)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the dataframe\n",
    "uni_df = uni_df[columns]\n",
    "uni_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 48 columns to worry about, much better than looking at almost 2000.\n",
    "\n",
    "I want to now look at what percentage of this data is missing, just to get a sense of the completeness of the data. I can get the percentage of non-missing values in each column by taking the result of the count method and dividing by the number of rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INSTNM              1.000000\n",
       "CITY                1.000000\n",
       "STABBR              1.000000\n",
       "ZIP                 1.000000\n",
       "NUMBRANCH           1.000000\n",
       "PREDDEG             1.000000\n",
       "HIGHDEG             1.000000\n",
       "LOCALE              0.147587\n",
       "LOCALE2             0.000000\n",
       "LATITUDE            0.147587\n",
       "LONGITUDE           0.147587\n",
       "CCBASIC             0.147587\n",
       "CCUGPROF            0.147587\n",
       "CCSIZSET            0.147587\n",
       "HBCU                0.145795\n",
       "PBI                 0.145795\n",
       "NANTI               0.145795\n",
       "MENONLY             0.147587\n",
       "WOMENONLY           0.147587\n",
       "RELAFFIL            0.020385\n",
       "ADM_RATE            0.286853\n",
       "SAT_AVG             0.178309\n",
       "DISTANCEONLY        0.943382\n",
       "UG                  0.000000\n",
       "CURROPER            0.157415\n",
       "NPT4_PUB            0.253608\n",
       "NPT4_PRIV           0.592231\n",
       "NPT4_PROG           0.000000\n",
       "NPT4_OTHER          0.000000\n",
       "NUM4_PUB            0.253918\n",
       "NUM4_PRIV           0.595573\n",
       "NUM4_PROG           0.000000\n",
       "NUM4_OTHER          0.000000\n",
       "TUITIONFEE_IN       0.569190\n",
       "TUITIONFEE_OUT      0.541147\n",
       "TUITFTE             0.941014\n",
       "INEXPFTE            0.941036\n",
       "AVGFACSAL           0.589664\n",
       "PFTFAC              0.525409\n",
       "PCTPELL             0.900266\n",
       "PCTFLOAN            0.900266\n",
       "DEP_STAT_PCT_IND    0.822643\n",
       "DEP_INC_AVG         0.822643\n",
       "IND_INC_AVG         0.822643\n",
       "GRAD_DEBT_MDN       0.993913\n",
       "WDRAW_DEBT_MDN      0.993913\n",
       "MN_EARN_WNE_P6      0.462705\n",
       "DATE                1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_df.count() / len(uni_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
